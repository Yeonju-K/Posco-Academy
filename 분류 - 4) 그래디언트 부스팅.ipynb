{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성:Series,DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# export_graphviz : 나무 구조 생성 및 저장 \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# graphviz : 나무 구조 시각화 (dot.확자아 파일 불러오기 등)\n",
    "import graphviz\n",
    "\n",
    "# 데이터 분할:train,test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 분류 Random Forest \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "# 최적 모델, 파라미터 탐색 \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 모델 성능 평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 한글 깨짐 방지\n",
    "import matplotlib.font_manager as fm \n",
    "font_list=[font.name for font in fm.fontManager.ttflist]\n",
    "font_list\n",
    "plt.rcParams['font.family']='NanumBarunGothic'\n",
    "\n",
    "# 나무 시각화 페이지\n",
    "\n",
    "# os환경\n",
    "import os\n",
    "\n",
    "# PATH 설정:graphviz 설치된 경로 지정\n",
    "os.environ['PATH']+=os.pathsep+'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 데이터 구성하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/piai/Downloads/3/HMEQ.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4bcab25f893d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/piai/Downloads/3/HMEQ.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1124\u001b[0m                     \u001b[0;34m'\"python-fwf\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 )\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_comment_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         f, handles = get_handle(\n\u001b[0m\u001b[1;32m   2265\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/piai/Downloads/3/HMEQ.csv'"
     ]
    }
   ],
   "source": [
    "df_raw=pd.read_csv(\"/home/piai/Downloads/3/HMEQ.csv\", engine='python')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 데이터 전처리 - 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.fillna(df_raw.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"JOB\"].fillna(\"Other\", inplace=True)\n",
    "df_raw.fillna(df_raw.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. 데이터 구성하기 - 더미변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies: 데이터의 문자형 변수에 대한 더미변수 생성\n",
    "df_raw_dummy=pd.get_dummies(df_raw)\n",
    "\n",
    "# 더미변수 생성된 데이터의 상위 5개 row를 확인\n",
    "df_raw_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. 데이터 구성하기 - 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수, 목표변수 데이터 지정 \n",
    "df_raw_x=df_raw_dummy.drop(\"BAD\", axis=1, inplace=False)\n",
    "df_raw_y=df_raw_dummy[\"BAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터를 7:3 비율로 분할한다. \n",
    "df_train_x,df_test_x,df_train_y,df_test_y=train_test_split(df_raw_x,df_raw_y,test_size=0.3,random_state=1234)\n",
    "print(\"train data X size : {}\".format(df_train_x.shape))\n",
    "print(\"train data Y size : {}\".format(df_train_y.shape))\n",
    "print(\"test data X size : {}\".format(df_test_x.shape))\n",
    "print(\"test data Y size : {}\".format(df_test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 \n",
    "df_train,df_test=train_test_split(df_raw_dummy, test_size=0.3,random_state=1234)\n",
    "print('train data size:{}'.format(df_train.shape))\n",
    "print('test data size:{}'.format(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래디언트 부스팅 생성 : GradientBoostingClassifer\n",
    "gb_uncustomized=GradientBoostingClassifier(random_state=1234)\n",
    "gb_uncustomized.fit(df_train_x, df_train_y)\n",
    "\n",
    "# Train 데이터 설명력 \n",
    "print(\"Accuracy on training set:{:.3f}\".format(gb_uncustomized.score(df_train_x,df_train_y)))\n",
    "\n",
    "# Test 데이터 설명력 \n",
    "print(\"Accuracy on test set:{:.3f}\".format(gb_uncustomized.score(df_test_x,df_test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 생성된 그래디언트 부스팅모델의 옵션 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_uncustomized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 모델 파라미터 조정 :  학습률 변경에 따른 모델 성능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 밒 test 정확도 결과 저장용 \n",
    "train_accuracy=[]; test_accuracy=[]\n",
    "\n",
    "# n_estimators: 트리 수 변경: 1~150 \n",
    "para_lr=[lr*0.1 for lr in range(1,10)] # 참조 : para_split:[10,20,30,...,150]\n",
    "\n",
    "for v_learning_rate in para_lr:\n",
    "    gb=GradientBoostingClassifier(random_state=1234,learning_rate=v_learning_rate)\n",
    "    gb.fit(df_train_x,df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x,df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x,df_test_y))\n",
    "    \n",
    "# 데이터 테이블로 저장 \n",
    "df_accuracy_lr=pd.DataFrame()\n",
    "df_accuracy_lr['learning_rate']=para_lr\n",
    "df_accuracy_lr['TrainAccuracy']=train_accuracy\n",
    "df_accuracy_lr['TestAccuracy']=test_accuracy\n",
    "\n",
    "# 모델 정확도 확인 \n",
    "df_accuracy_lr.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_lr,train_accuracy,linestyle='-',label='train_accuracy')\n",
    "plt.plot(para_lr,test_accuracy,linestyle='--',label='test_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test 데이터의 성능 변화를 고려하여 0.4, 0.7이 선택지가 될 수 있는데, 이번에는 0.4를 선택하기로 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 모델 파라미터 조정 : 트리수 변경에 따른 모델 성능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 밒 test 정확도 결과 저장용 \n",
    "train_accuracy=[]; test_accuracy=[]\n",
    "\n",
    "# n_estimators: 트리 수 변경: 1~150 \n",
    "para_n_tree=[n_tree*10 for n_tree in range(1,16)] # 참조 : para_split:[10,20,30,...,150]\n",
    "\n",
    "for v_n_estimators in para_n_tree:\n",
    "    gb=GradientBoostingClassifier(random_state=1234,learning_rate=0.4, \\\n",
    "                              n_estimators=v_n_estimators)\n",
    "    gb.fit(df_train_x,df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x,df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x,df_test_y))\n",
    "    \n",
    "# 데이터 테이블로 저장 \n",
    "df_accuracy_n=pd.DataFrame()\n",
    "df_accuracy_n['n_estimators']=para_n_tree\n",
    "df_accuracy_n['TrainAccuracy']=train_accuracy\n",
    "df_accuracy_n['TestAccuracy']=test_accuracy\n",
    "\n",
    "# 모델 정확도 확인 \n",
    "df_accuracy_n.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_n_tree,train_accuracy,linestyle='-',label='train_accuracy')\n",
    "plt.plot(para_n_tree,test_accuracy,linestyle='--',label='test_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test 데이터의 성능 변화를 고려하여 70과 100을 고려할 수 있는데 train_accuracy와 test_accuracy차의 차이가 크지 않으므로 높은 정확도를 보이는 100을 선택하기로 하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5 모델 파라미터 조정 : 최대 깊이 변경에 따른 모델 성능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 밒 test 정확도 결과 저장용 \n",
    "train_accuracy=[]; test_accuracy=[]\n",
    "\n",
    "# max_depth: 최대 깊이 변경\n",
    "para_depth=[depth for depth in range(1,11)] # 참조 : para_depth:[1,2,3,...,10]\n",
    "\n",
    "for v_max_depth in para_depth:\n",
    "    gb=GradientBoostingClassifier(random_state=1234,n_estimators=100, learning_rate=0.4,\\\n",
    "                                  max_depth=v_max_depth)\n",
    "    gb.fit(df_train_x,df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x,df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x,df_test_y))\n",
    "    \n",
    "# 데이터 테이블로 저장 \n",
    "df_accuracy_depth=pd.DataFrame()\n",
    "df_accuracy_depth['Depthdepth']= para_depth\n",
    "df_accuracy_depth['TrainAccuracy']=train_accuracy\n",
    "df_accuracy_depth['TestAccuracy']=test_accuracy\n",
    "\n",
    "# 모델 정확도 확인 \n",
    "df_accuracy_depth.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_depth,train_accuracy,linestyle='-',label='Train accuracy')\n",
    "plt.plot(para_depth,test_accuracy,linestyle='--',label='Test accuracy')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('max depth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최대 깊이 증가에 따라 모델의 정확도는 증가하며 train/test 데이터의 성능 변화를 고려하여 9를 선택한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5 모델 파라미터 조정 : 분리 노드의 최소 자료 수 변경에 따른 모델 성능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 밒 test 정확도 결과 저장용 \n",
    "train_accuracy=[]; test_accuracy=[]\n",
    "\n",
    "# min_samples_split : 분할하기 위한 노드의 최소 샘플 수 \n",
    "para_split=[n_split*10 for n_split in range(1,11)] # 참조 : para_split:[1,2,3,...,10]\n",
    "\n",
    "for v_min_samples_split in para_split:\n",
    "    gb=GradientBoostingClassifier(random_state=1234,n_estimators=100, max_depth=9 \\\n",
    "                              ,learning_rate=0.4,min_samples_split=v_min_samples_split)\n",
    "    gb.fit(df_train_x,df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x,df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x,df_test_y))\n",
    "    \n",
    "# 데이터 테이블로 저장 \n",
    "df_accuracy_depth=pd.DataFrame()\n",
    "df_accuracy_depth['MinSamplesSplit']= para_depth\n",
    "df_accuracy_depth['TrainAccuracy']=train_accuracy\n",
    "df_accuracy_depth['TestAccuracy']=test_accuracy\n",
    "\n",
    "# 모델 정확도 확인 \n",
    "df_accuracy_depth.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_split,train_accuracy,linestyle='-',label='Train accuracy')\n",
    "plt.plot(para_split,test_accuracy,linestyle='--',label='Test accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('min samples split')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분리 노드의 최소  자료 수 증가에 따라 모델의 정확도가 일정하고, test 데이터의 성능 변화를 고려하였을 때, test accuracy가 상대적으로 큰 90을 선택한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5 모델 파라미터 조정 : 잎사귀 노드의 최소 자료 수 변경에 따른 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 밒 test 정확도 결과 저장용 \n",
    "train_accuracy=[]; test_accuracy=[]\n",
    "\n",
    "# min_samples_split : 분할하기 위한 노드의 최소 샘플 수 \n",
    "para_leaf=[n_leaf for n_leaf in range(1,11)] # 참조 : para_leaf:[1,2,3,...,10]\n",
    "\n",
    "for v_min_samples_leaf in para_leaf:\n",
    "    gb=GradientBoostingClassifier(random_state=1234,n_estimators=100, max_depth=9 \\\n",
    "                                  ,learning_rate=0.4,min_samples_split=90,\\\n",
    "                                  min_samples_leaf=v_min_samples_leaf)\n",
    "    gb.fit(df_train_x,df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x,df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x,df_test_y))\n",
    "    \n",
    "# 데이터 테이블로 저장 \n",
    "df_accuracy_depth=pd.DataFrame()\n",
    "df_accuracy_depth['MinSamplesSplit']= para_depth\n",
    "df_accuracy_depth['TrainAccuracy']=train_accuracy\n",
    "df_accuracy_depth['TestAccuracy']=test_accuracy\n",
    "\n",
    "# 모델 정확도 확인 \n",
    "df_accuracy_depth.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설명력 그래프 확인\n",
    "plt.plot(para_leaf,train_accuracy,linestyle='-',label='Train accuracy')\n",
    "plt.plot(para_leaf,test_accuracy,linestyle='--',label='Test accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('min samples leaf')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
